# üöÄ Execora Quick Start Guide

Get Execora running in under 5 minutes!

**Features**: Real-time voice commands in Hindi/English, multi-command conversations with memory, parallel task execution (3 concurrent), instant 2ms responses, and 95% latency reduction through smart caching.

## üÜï What's New

Recent updates include:
- ‚úÖ **Per-conversation memory**: Say "Check balance" after mentioning a customer ‚Üí system remembers!
- ‚úÖ **Parallel task execution**: Execute 3 commands simultaneously (was sequential before)
- ‚úÖ **Response templates**: 2ms responses for 99% of commands (was 1200ms with LLM)
- ‚úÖ **3-layer caching**: Customer search, balance queries, conversation context
- ‚úÖ **Database validation**: Fails fast with clear errors if schema is incomplete

See [IMPLEMENTATION_DETAILS.md](docs/implementation/IMPLEMENTATION_DETAILS.md) for technical breakdown.

## ‚ö° Fastest Start (Docker)

```bash
# 1. Clone and enter directory
git clone <repository>
cd execora

# 2. Create environment file
cp .env.example .env

# 3. Add your OpenAI API key to .env
# OPENAI_API_KEY=sk-your-key-here

# 4. Start everything with Docker
docker-compose up -d

# 5. Wait 30 seconds for services to start, then initialize database
docker-compose exec app npx prisma db push

# 6. Load sample data (optional)
docker-compose exec app npx prisma db seed

# 7. Open browser
open http://localhost:3000
```

Done! Execora is running.

## üß™ Test the System

### Via Web Interface

1. Open http://localhost:3000
2. Wait for "Connected" status
3. Type: "Rahul ka balance batao"
4. Click "Send" ‚Üí See instant response (2ms template response!)
5. Try second command without repeating customer name ‚Üí Memory works!

### Via API

```bash
# Search customer (instant with cache)
curl http://localhost:3000/api/v1/customers/search?q=Rahul

# Create invoice (runs in parallel with other tasks)
curl -X POST http://localhost:3000/api/v1/invoices \
  -H "Content-Type: application/json" \
  -d '{
    "customerId": "<customer-id>",
    "items": [
      {"productName": "Milk", "quantity": 2}
    ]
  }'

# Check daily summary
curl http://localhost:3000/api/v1/summary/daily
```

### Performance Improvements (New!)
- ‚úÖ 2ms response time for common commands (templates)
- ‚úÖ Multi-command conversations with 5min memory
- ‚úÖ 3 parallel task execution per conversation
- ‚úÖ Smart caching with 95% latency reduction
- ‚úÖ 65% reduction in API costs

## üì± Add WhatsApp (Optional)

To enable WhatsApp reminders:

1. Get WhatsApp Business API credentials
2. Add to `.env`:
```env
WHATSAPP_PHONE_NUMBER_ID=your_phone_id
WHATSAPP_ACCESS_TOKEN=your_token
WHATSAPP_WEBHOOK_VERIFY_TOKEN=any_random_string
```

3. Restart:
```bash
docker-compose restart app worker
```

## üîç View Logs

```bash
# All logs
docker-compose logs -f

# Just app
docker-compose logs -f app

# Just worker
docker-compose logs -f worker
```

## üõ†Ô∏è Useful Commands

```bash
# Stop everything
docker-compose down

# Restart after code changes
docker-compose up -d --build

# Access database
docker-compose exec postgres psql -U execora -d execora

# View MinIO files
open http://localhost:9001  # admin / minioadmin

# Database UI
npm run db:studio
```

## üéôÔ∏è Voice Commands to Try

### Single Commands
1. **Check Balance**: "Rahul ka balance batao"
2. **Create Invoice**: "Rahul ko 2 milk aur 1 bread ka bill bana do"
3. **Record Payment**: "Rahul ne 200 cash me diye"
4. **Schedule Reminder**: "Suresh ko 1500 ka reminder kal 7 baje bhejna"
5. **Check Stock**: "Milk ka stock kitna hai"

### Multi-Command Conversations (New!)
Try these back-to-back to see **conversation memory** in action:

```
1. Say: "Rahul ka balance check karo"
   Get: "Rahul ka balance 500 rupees hai"

2. Say: "Ab invoice bana de" (without saying Rahul again!)
   System remembers: You meant Rahul!
   Get: Bill created for Rahul

3. Say: "Stock check karo"
   Get: Stock information (still remembers Rahul in context)
```

**Note**: The system remembers customer context for 5 minutes!

## üêõ Troubleshooting

### Connection Failed?
```bash
# Check services are running
docker-compose ps

# Restart everything
docker-compose restart
```

### Database Error?
```bash
# Reset database
docker-compose down -v
docker-compose up -d
docker-compose exec app npx prisma db push
docker-compose exec app npx prisma db seed
```

### Port Already in Use?
Edit `docker-compose.yml` and change port mappings:
```yaml
ports:
  - "3001:3000"  # Changed from 3000:3000
```

## üìñ Next Steps

### For Users
1. Read [README.md](README.md) for full feature list
2. Explore API at http://localhost:3000/api/
3. Try multi-command conversations
4. Enable WhatsApp integration (optional)

### For Developers
1. Review [DEVELOPER_GUIDE.md](docs/implementation/DEVELOPER_GUIDE.md) for technical details
2. Check [IMPLEMENTATION_DETAILS.md](docs/implementation/IMPLEMENTATION_DETAILS.md) for what's new
3. Study `prisma/schema.prisma` for database schema
4. Explore `src/integrations/openai.ts` for LLM customization
5. See [ARCHITECTURE.md](docs/architecture/ARCHITECTURE.md) for system design

## üéâ You're Ready!

Execora is now processing voice commands in real-time with:
- ‚ú® **Instant responses** (2ms for common commands)
- üß† **Conversation memory** (remembers customer context)
- ‚ö° **Parallel execution** (up to 3 tasks simultaneously)
- üí∞ **Cost-optimized** (95% latency reduction, 65% cheaper)

Try speaking or typing commands to see the AI in action.

For production deployment, see [README.md](README.md) security notes.
For developers, see [DEVELOPER_GUIDE.md](docs/implementation/DEVELOPER_GUIDE.md).
